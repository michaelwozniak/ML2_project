{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.397859Z",
     "start_time": "2021-01-04T00:32:21.956099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "import ngboost\n",
    "import talib\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "plt.style.use(\"ggplot\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.444823Z",
     "start_time": "2021-01-04T00:32:24.399858Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../dataset/spx.csv\",\n",
    "    parse_dates=[\"Date\"],\n",
    "    names=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"],\n",
    "    header=0,\n",
    "    index_col=\"Date\")\n",
    "df = df[df.index < \"2020-10-01\"]\n",
    "df[\"rr\"] = (np.log(df.Close) - np.log(df.Close.shift(1))) * 100\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.460812Z",
     "start_time": "2021-01-04T00:32:24.446817Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"day_of_week\"] = df.index.dayofweek\n",
    "df[\"day_of_year\"] = df.index.dayofyear\n",
    "df[\"week\"] = df.index.week\n",
    "df[\"quarter\"] = df.index.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.476801Z",
     "start_time": "2021-01-04T00:32:24.462809Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Open_stationary\"] = df[\"Open\"].diff()\n",
    "df[\"High_stationary\"]= df[\"High\"].diff()\n",
    "df[\"Low_stationary\"]= df[\"Low\"].diff()\n",
    "df[\"Close_stationary\"]= df[\"Close\"].diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T17:24:30.347647Z",
     "start_time": "2021-01-03T17:24:30.308650Z"
    }
   },
   "source": [
    "## Intra day relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.492793Z",
     "start_time": "2021-01-04T00:32:24.478814Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Close_minus_Open\"] = df[\"Close\"] - df[\"Open\"]\n",
    "df[\"High_minus_Low\"] = df[\"High\"] - df[\"Low\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow technical analysis variables and ARMA proxy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.524786Z",
     "start_time": "2021-01-04T00:32:24.494792Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"MA\"] = talib.MA(df[\"rr\"], timeperiod=2)\n",
    "df[\"EMA\"] = talib.EMA(df[\"rr\"], timeperiod=2)\n",
    "df[\"STD\"] = talib.STDDEV(df[\"rr\"], timeperiod=2)\n",
    "df[\"MA_2\"] = talib.MA(df[\"rr\"], timeperiod=3)\n",
    "df[\"EMA_2\"] = talib.EMA(df[\"rr\"], timeperiod=3)\n",
    "df[\"STD_2\"] = talib.STDDEV(df[\"rr\"], timeperiod=3)\n",
    "df[\"MA_W\"] = talib.MA(df[\"rr\"], timeperiod=6)\n",
    "df[\"EMA_W\"] = talib.EMA(df[\"rr\"], timeperiod=6)\n",
    "df[\"STD_W\"] = talib.STDDEV(df[\"rr\"], timeperiod=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility Indicators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.539768Z",
     "start_time": "2021-01-04T00:32:24.527773Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"ATR\"] = talib.ATR(df[\"High\"], df[\"Low\"], df[\"Close\"], timeperiod=7)\n",
    "df[\"TRANGE\"] = talib.TRANGE(df[\"High\"], df[\"Low\"], df[\"Close\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Indicators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.555763Z",
     "start_time": "2021-01-04T00:32:24.541765Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"OBV\"] = talib.OBV(df[\"Close\"],df[\"Volume\"])\n",
    "df[\"ADOSC\"] = talib.ADOSC(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.571750Z",
     "start_time": "2021-01-04T00:32:24.558753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'rr', 'day_of_week',\n",
       "       'day_of_year', 'week', 'quarter', 'Open_stationary', 'High_stationary',\n",
       "       'Low_stationary', 'Close_stationary', 'Close_minus_Open',\n",
       "       'High_minus_Low', 'MA', 'EMA', 'STD', 'MA_2', 'EMA_2', 'STD_2', 'MA_W',\n",
       "       'EMA_W', 'STD_W', 'ATR', 'TRANGE', 'OBV', 'ADOSC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.587752Z",
     "start_time": "2021-01-04T00:32:24.574746Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['rr', 'day_of_week','day_of_year', 'week', 'quarter', \n",
    "         'Volume','Open_stationary', 'High_stationary',\n",
    "       'Low_stationary', 'Close_stationary', 'Close_minus_Open',\n",
    "       'High_minus_Low', 'MA', 'EMA', 'STD', 'MA_2', 'EMA_2', 'STD_2', 'MA_W',\n",
    "       'EMA_W', 'STD_W', 'ATR', 'TRANGE', 'OBV', 'ADOSC']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables lagging/shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.794627Z",
     "start_time": "2021-01-04T00:32:24.591737Z"
    }
   },
   "outputs": [],
   "source": [
    "to_lag = ['rr', 'Volume', 'Open_stationary', 'High_stationary', 'Low_stationary','Close_stationary', \n",
    "          'Close_minus_Open', 'High_minus_Low', 'MA', 'EMA',  'STD', 'MA_2', 'EMA_2', 'STD_2', 'MA_W', 'EMA_W', \n",
    "          'STD_W', 'ATR', 'TRANGE', 'OBV', 'ADOSC']\n",
    "\n",
    "for i in to_lag:\n",
    "    for j in range(1,4):\n",
    "        col_name = i + \"_L\" + str(j)\n",
    "        df[col_name] = df[i].shift(j)\n",
    "    if i != \"rr\":\n",
    "        df.drop(columns = [i], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.810623Z",
     "start_time": "2021-01-04T00:32:24.796629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7664, 68)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.826613Z",
     "start_time": "2021-01-04T00:32:24.812608Z"
    }
   },
   "outputs": [],
   "source": [
    "features = set(df.columns)\n",
    "features.remove(\"rr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection using tree-based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"NGBoost does provide methods to interpret models fit with regression tree base learners. Since each parameter in the distribution is fit by a separate sequence of learners, there will be multiple model interpretation results, one for each parameter. The default distribution used is Normal so the following example shows results for the loc and scale parameters.\" [source](https://stanfordmlgroup.github.io/ngboost/3-interpretation.html)\n",
    "\n",
    "Taking above into consideration I will assume that my default NGBoost model consists of: \n",
    "* Normal distribution as the output distribution\n",
    "* 3-depth Decision Tree as the base learner\n",
    "* 500 iterations as the number of boosting iterations\n",
    "* 0.01 learning rate\n",
    "* negative log likelihood score as scoring function\n",
    "\n",
    "During next modeling steps I will tune this parameters but now I will fix them!\n",
    "\n",
    "Here I would like to find the best variables on average in each of the training-validation periods and in each of distribution parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T00:32:24.842604Z",
     "start_time": "2021-01-04T00:32:24.828600Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = [\"2006-01-12\", \"2008-01-15\", \"2014-01-13\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-validation period 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T01:38:14.175742Z",
     "start_time": "2021-01-04T00:32:24.844590Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 252/252 [1:05:49<00:00, 15.67s/it]\n"
     ]
    }
   ],
   "source": [
    "loc_list = list()\n",
    "scale_list = list()\n",
    "\n",
    "start = starts[0]\n",
    "df_tmp = df.loc[start:].head(252 * 4).copy()\n",
    "\n",
    "for i in tqdm(range(0, 252)):\n",
    "    train = df_tmp.iloc[i : i + 252 * 3].copy()\n",
    "    ngb = ngboost.NGBRegressor(\n",
    "        Dist=ngboost.distns.Normal,\n",
    "        Score=ngboost.scores.LogScore,\n",
    "        Base=DecisionTreeRegressor(criterion=\"friedman_mse\", max_depth=3),\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        minibatch_frac=1.0,\n",
    "        col_sample=1.0,\n",
    "        verbose=False,\n",
    "        verbose_eval=500,\n",
    "        tol=0.0001,\n",
    "        random_state=2021)\n",
    "    ngb.fit(train[features], train.rr)\n",
    "    \n",
    "    feature_importance_loc = ngb.feature_importances_[0]\n",
    "    feature_importance_scale = ngb.feature_importances_[1]\n",
    "    df_loc = pd.DataFrame({'feature':list(features),\n",
    "                           'importance':feature_importance_loc}).sort_values('importance',ascending=False)\n",
    "    df_scale = pd.DataFrame({'feature':list(features),\n",
    "                           'importance':feature_importance_scale}).sort_values('importance',ascending=False)    \n",
    "    df_loc[\"index\"] = np.arange(1,68)\n",
    "    df_loc.drop(columns=[\"importance\"], inplace=True)\n",
    "    df_scale[\"index\"] = np.arange(1,68)\n",
    "    df_scale.drop(columns=[\"importance\"], inplace=True)\n",
    "    loc_list.append(df_loc)\n",
    "    scale_list.append(df_scale)\n",
    "\n",
    "loc_df1 = pd.concat(loc_list)\n",
    "scale_df1 = pd.concat(scale_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-validation period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T03:47:22.791303Z",
     "start_time": "2021-01-04T02:42:39.709035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 252/252 [1:04:25<00:00, 15.34s/it]\n"
     ]
    }
   ],
   "source": [
    "loc_list = list()\n",
    "scale_list = list()\n",
    "\n",
    "start = starts[1]\n",
    "df_tmp = df.loc[start:].head(252 * 4).copy()\n",
    "\n",
    "for i in tqdm(range(0, 252)):\n",
    "    train = df_tmp.iloc[i : i + 252 * 3].copy()\n",
    "    ngb = ngboost.NGBRegressor(\n",
    "        Dist=ngboost.distns.Normal,\n",
    "        Score=ngboost.scores.LogScore,\n",
    "        Base=DecisionTreeRegressor(criterion=\"friedman_mse\", max_depth=3),\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        minibatch_frac=1.0,\n",
    "        col_sample=1.0,\n",
    "        verbose=False,\n",
    "        verbose_eval=500,\n",
    "        tol=0.0001,\n",
    "        random_state=2021)\n",
    "    ngb.fit(train[features], train.rr)\n",
    "    \n",
    "    feature_importance_loc = ngb.feature_importances_[0]\n",
    "    feature_importance_scale = ngb.feature_importances_[1]\n",
    "    df_loc = pd.DataFrame({'feature':list(features),\n",
    "                           'importance':feature_importance_loc}).sort_values('importance',ascending=False)\n",
    "    df_scale = pd.DataFrame({'feature':list(features),\n",
    "                           'importance':feature_importance_scale}).sort_values('importance',ascending=False)    \n",
    "    df_loc[\"index\"] = np.arange(1,68)\n",
    "    df_loc.drop(columns=[\"importance\"], inplace=True)\n",
    "    df_scale[\"index\"] = np.arange(1,68)\n",
    "    df_scale.drop(columns=[\"importance\"], inplace=True)\n",
    "    loc_list.append(df_loc)\n",
    "    scale_list.append(df_scale)\n",
    "\n",
    "loc_df2 = pd.concat(loc_list)\n",
    "scale_df2 = pd.concat(scale_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training-validation period 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T03:47:22.791303Z",
     "start_time": "2021-01-04T02:42:39.709035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 252/252 [1:04:43<00:00, 15.41s/it]\n"
     ]
    }
   ],
   "source": [
    "loc_list = list()\n",
    "scale_list = list()\n",
    "\n",
    "start = starts[2]\n",
    "df_tmp = df.loc[start:].head(252 * 4).copy()\n",
    "\n",
    "for i in tqdm(range(0, 252)):\n",
    "    train = df_tmp.iloc[i : i + 252 * 3].copy()\n",
    "    ngb = ngboost.NGBRegressor(\n",
    "        Dist=ngboost.distns.Normal,\n",
    "        Score=ngboost.scores.LogScore,\n",
    "        Base=DecisionTreeRegressor(criterion=\"friedman_mse\", max_depth=3),\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        minibatch_frac=1.0,\n",
    "        col_sample=1.0,\n",
    "        verbose=False,\n",
    "        verbose_eval=500,\n",
    "        tol=0.0001,\n",
    "        random_state=2021)\n",
    "    ngb.fit(train[features], train.rr)\n",
    "    \n",
    "    feature_importance_loc = ngb.feature_importances_[0]\n",
    "    feature_importance_scale = ngb.feature_importances_[1]\n",
    "    df_loc = pd.DataFrame({'feature':list(features),\n",
    "                           'importance':feature_importance_loc}).sort_values('importance',ascending=False)\n",
    "    df_scale = pd.DataFrame({'feature':list(features),\n",
    "                           'importance':feature_importance_scale}).sort_values('importance',ascending=False)    \n",
    "    df_loc[\"index\"] = np.arange(1,68)\n",
    "    df_loc.drop(columns=[\"importance\"], inplace=True)\n",
    "    df_scale[\"index\"] = np.arange(1,68)\n",
    "    df_scale.drop(columns=[\"importance\"], inplace=True)\n",
    "    loc_list.append(df_loc)\n",
    "    scale_list.append(df_scale)\n",
    "\n",
    "loc_df3 = pd.concat(loc_list)\n",
    "scale_df3 = pd.concat(scale_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
